<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Portfólio de projetos de Ciência de dados</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Portfólio</strong> de projetos de Ciência de dados</a>
								</header>

							<!-- Banner -->
								<section id="banner">
									<div class="content">
										<header>
											<h1>Olá, seja muito bem-vindo (a) ao meu portfólio de projetos de Ciência de Dados.</h1>
										</header>
										<p>Nessa página, eu demonstro minhas habilidades de resolver problemas de negócio utilizando conceitos e ferramentas da Ciência de Dados, através de projetos com dados públicos.</p>
										<p>Você vai encontrar também, minhas experiências profissionais, habilidades, ferramentas e conceitos envolvendo a Ciência de Dados.</p>
										<p></p>
										<p>Sinta-se à vontade para entrar em contato através dos links no final da página.</p>
									</div>
									<span class="image object">
										<img src="images/profile_picture2.jpg" alt="" />
									</span>
								</section>

								<!-- Content -->
									<section>
										<header class="main">
											<h1>Sobre mim</h1>
										</header>

										<!-- Content -->
											<p>Meu nome é Gabriel Alves, sou formado em Ciências Econômicas, e ao longo dos meus mais de 7 anos de carreira, atuei como Consultor de Risco em empresas como EY e Deloitte. Durante essa trajetória, desenvolvi uma visão analítica aguçada e a habilidade de transformar dados complexos em informações estratégicas.</p>
											<p>Nos últimos 6 meses, como Analista de Dados especializado em Big Data na Tahto, tenho desempenhado um papel ativo no time, indo além da consolidação de indicadores e curadoria de KPIs. Minha contribuição estende-se à aplicação de metodologias avançadas de análise de dados, resultando em análises robustas. Minha abordagem proativa e focada em resultados tem gerado insights valiosos, otimizando a tomada de decisões para o cliente Oi.</p>
											<p>Meu objetivo é solidificar minha atuação na área de Dados, visando aprimorar a tomada de decisões empresariais por meio da criação de soluções fundamentadas em dados atuando como Cientista de Dados. Estou entusiasmado com a perspectiva de contribuir significativamente para a inovação e o sucesso, proporcionando insights valiosos para aprimorar a tomada de decisões da empresa.</p>
											</section>

							<!-- Section -->
								<section>
									<header class="major">
										<h1>Habilidades</h1>
									</header>
									<div class="features">
										<article>
											<span class="icon fa-gem"></span>
											<div class="content">
												<h3>Linguagens de Programação e Banco de Dados</h3>
												<ul>
													<li>Python para análise de dados;</li>
													<li>SQL para extração de dados;</li>
													<li>Banco de Dados: SQLite, Postres e MySQL.</li>
												</ul>
											</div>
										</article>
										<article>
											<span class="icon solid fa-paper-plane"></span>
											<div class="content">
												<h3>Estatística e Machine Learning</h3>
												<ul>
													<li>Estatística descritiva;</li>
													<li>Teste A/B;</li>
													<li>Algoritmos de Regressão, classificação e clusterização;</li>
													<li>Deep Learning, Generative AI e LLM </li>
													<li>Técnicas de balanceamento dos dados, seleção de atributos e redução de dimensionalidade;</li>
													<li>Métricas de performance dos algoritmos ( RMSE, MAE, MAPE, Confusion Matrix, Precisão, Recall, Curva ROC, Curva Lift, AUC, Silhouette Score, F1);</li>
													<li>Pacotes de Machine Learning: Sklearn e Scipy.</li>
												</ul>
											</div>
										</article>
										<article>
											<span class="icon solid fa-rocket"></span>
											<div class="content">
												<h3>Visualização de Dados</h3>
												<ul>
													<li>Matplotlib, Seaborn e Plotly;</li>
													<li>Metabase;</li>
													<li>PowerBI.</li>
													</ul>
											</div>
										</article>
										<article>
											<span class="icon solid fa-signal"></span>
											<div class="content">
												<h3>Desenvolvimento de Aplicações</h3>
												<ul>
													<li>Git, Github, Gitlab, Cookiecutter e Virtual Environment;</li>
													<li>Webscraping, Streamlit, Flask e Python API's.</li>
													<li>Cloud Render, AWS e GCP</li>
												</ul>
											</div>
										</article>
									</div>
								</section>

								<!-- Experiência -->
									<section>
										<header class="main">
											<h1>Experiências profissionais</h1>
										</header>
											<h2 id="content">Analista de dados</h2>
											<p>Na posição atual como Analista de Dados Sênior com ênfase em Big Data na Tahto, venho desempenhando um papel crucial na estruturação de indicadores e Dashboards. Ao longo dos últimos seis meses, concentrei meus esforços na automação desses processos, proporcionando uma análise eficiente e detalhada das principais métricas. Minha abordagem orientada para resultados tem sido fundamental para o sucesso dessas iniciativas, reforçando minha expertise em Big Data e Ciência de Dados.</p>
											<h2 id="content">Consultoria de negócios</h2>
											<p>Com uma carreira abrangendo mais de seis anos em consultoria nas empresas BKR – Lopes e Machado Auditores, Deloitte, Inetum e EY, destaco minha constante busca por uma abordagem analítica em todas as entregas, com foco primordial em dados. Ao longo desse período, liderei a estruturação de metodologias voltadas para a área de controles internos na BKR, implementei a automação do preenchimento de processos e conduzi treinamentos de conscientização LGPD na Inetum. Na Deloitte, participei ativamente da elaboração de Dashboards para avaliação de desempenho e otimização de processos. Já na EY, contribuí significativamente para o design de um dashboard estratégico direcionado à gestão de riscos em Fundos de Pensão. Essa jornada diversificada e dinâmica reflete meu compromisso constante em proporcionar soluções analíticas e impulsionar resultados eficazes em cada projeto.</p>											
								</section>
							<!-- Section -->
								<section>
									<header class="major">
										<h2>Projetos em Ciência de Dados</h2>
									</header>
										<p>Durante minha jornada na Ciência de Dados, dediquei-me à criação de soluções para desafios empresariais reais, utilizando dados públicos provenientes de sites e competições de Ciência de Dados. Cada projeto que apresentarei a seguir representa desde a identificação dos desafios de negócio até a implementação efetiva dos algoritmos em produção, fazendo uso de avançadas ferramentas de Cloud Computing. Vale mencionar que, devido ao seu alto custo operacional, alguns projetos foram retirados de produção; entretanto, os códigos correspondentes estão disponíveis no GitHub para referência e aprendizado contínuo.</p>
									<div class="posts">
										<article>
											<a href="https://github.com/GabrielAlvesDS/File-Insight" class="image"><img src="images/file-insight.png" alt="" /></a>
											<h3>File-Insight - Análise de Arquivos CSV e DOCX com LangChain e OpenAI</h3>
											<p>Este projeto implementa uma aplicação web que permite aos usuários fazer upload de arquivos CSV ou DOCX e realizar consultas automatizadas sobre os dados, utilizando a API OpenAI e LangChain.</p>
											<p> aplicação foi construída com Streamlit e utiliza um agente de LangChain para processar as consultas de CSV e extrair informações de arquivos DOCX.</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
                                                                                        	<li><strong>Versionamento e Deploy:</strong> Git, GitHub</li>
                                                                                        	<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas</li>
                                                                                        	<li><strong>Desenvolvimento Web:</strong> Streamlit</li>
                                                                                            	<li><strong>IA e Modelos de Linguagem:</strong> LangChain, OpenAI API</li>

											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/File-Insight" class="button">Saiba mais</a></li>
											</ul>
										</article>


										<article>
											<a href="https://github.com/GabrielAlvesDS/LSTM-TempForecast" class="image"><img src="images/LSTM_Forecast.png" alt="" /></a>
											<h3>LSTM_Forecast - Temperature Forecasting Long Short Term Model</h3>
											<p>Um modelo LSTM foi desenvolvido para prever a temperatura do ar para a próxima hora com base nas últimas 24 horas de dados históricos. O modelo apresentou um desempenho excepcional, com um Erro Quadrático Médio (MSE) de 0,80 e um Erro Quadrático Médio da Raiz (RMSE) de 0,89, indicando que as previsões de temperatura desviaram menos de 1 grau Celsius em média.</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitHub</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Machine Learning:</strong> Redes Neurais, MLP, GRU, LSTM</li>

											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/LSTM-TempForecast" class="button">Saiba mais</a></li>
											</ul>
										</article>

										

										<article>
											<a href="https://github.com/GabrielAlvesDS/TempTrack" class="image"><img src="images/TempTrack.png" alt="" /></a>
											<h3>TempTrack - Time Series Temperature Forecasting Model</h3>
											<p>Este projeto de análise de séries temporais envolve o desenvolvimento de dois modelos para prever a temperatura horária ao longo de um ano, utilizando Prophet e XGBoost. O objetivo é avaliar a eficácia de cada modelo e determinar qual deles oferece o melhor desempenho.</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitHub</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Previsão:</strong> Prophet, XGBoost</li>

											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/TempTrack" class="button">Saiba mais</a></li>
											</ul>
										</article>

										<article>
											<a href="https://github.com/GabrielAlvesDS/CarPrice_Pro" class="image"><img src="images/CarPrice Pro.jpg" alt="" /></a>
											<h3>CarPrice Pro - Precificador de carro</h3>
											<p>Consiste em um projeto com base em dados extraídos da API do WebMotors que busca criar um modelo de predição do valor de venda de um carro dado suas características. Criando uma interface com o Telegram para consultas.</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitHub</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Machine Learning:</strong> Logistic Regression, K-Nearest Neighbors, Random Forest, XGBoost Classifier</li>
												<li><strong>Automação e Desenvolvimento Web:</strong> Google Apps Script, Flask</li>

											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/CarPrice_Pro" class="button">Saiba mais</a></li>
											</ul>
										</article>										

										<article>
											<a href="https://github.com/GabrielAlvesDS/fraud_risk_defender" class="image"><img src="images/fraud_risk.jpg" alt="" /></a>
											<h3>Fraud Risk Defender - Detecção de fraudes</h3>
											<p>Elaboração de um modelo de classificação para detecção de fraude em transações financeiras realizadas através de dispositivos móveis. Com 99,58% de Recall e 99,79% de ROC AUC, onde no cenário estipulado geraria uma receita de 537 milhões (moeda não especificada).</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitHub</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Machine Learning:</strong> Logistic Regression, K-Nearest Neighbors, Random Forest, XGBoost Classifier, Gradient Boosting</li>
												<li><strong>Seleção de Features:</strong> Boruta</li>

											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/fraud_risk_defender" class="button">Saiba mais</a></li>
											</ul>
										</article>
										
										<article>
											<a href="https://github.com/GabrielAlvesDS/rossmann-sale-prediction" class="image"><img src="images/sales_prediction.jpg" alt="" /></a>
											<h3>Construção de um modelo de predição de vendas para uma rede de Drogarias</h3>
											<p>Construção de um algoritmo de Machine Learning para prever vendas com 6 semanas de antecedência em uma rede de farmácias da Europa. O algoritmo de regressão treinado possui 10,5% de MAPE.</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitHub</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Machine Learning:</strong> K-Means, Hierarchical Clustering, DBScan</li>
												<li><strong>Infraestrutura em Nuvem:</strong> AWS Cloud (EC2, S3, Postgres, SQLite)</li>
												<li><strong>Visualização:</strong> Metabase</li>


											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/rossmann-sale-prediction" class="button">Saiba mais</a></li>
											</ul>
										</article>
										<article>
											<a href="https://github.com/GabrielAlvesDS/Health-Insurance-Cross-Sell/tree/main" class="image"><img src="images/customer_loyalty.jpg" alt="" /></a>
											<h3>Health Insurance Cross Sell - Ranqueamento dos clientes mais propensos a comprar um novo produto.</h3>
											<p>Identificação de clientes propensos a adquirir um novo produto de uma seguradora. Implantando um modelo de machine learning conectado a uma API e uma planilha do Google Sheets, conseguindo triplicar a eficiência do time de Vendas.</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitHub, Render</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Machine Learning:</strong> Scikit-Learn, XGBoost</li>
												<li><strong>Desenvolvimento Web e Automação:</strong> Flask, Pickle, Google Apps Script, Google Sheets</li>

											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/Health-Insurance-Cross-Sell/tree/main" class="button">Saiba mais</a></li>
											</ul>
										</article>
										<article>
											<a href="#" class="image"><img src="images/clustering.jpg" alt="" /></a>
											<h3>Construção de um programa de fidelidade com clusterização de clientes</h3>
											<p>Eu usei Python, Estatística e técnicas não-supervisionadas de Machine Learning para segmentar um grupo de clientes com base em suas características de performance de compra, a fim de selecionar grupos de clientes para formar um programa de Fidelidade com o objetivo de aumentar a receita da empresa. E o resultado dessa solução, caso fosse implementada, seria de R$ 15MM de dólares de receita anual.</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitLab, GitHub</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Machine Learning:</strong> K-Means, Hierarchical Clustering, DBScan</li>
												<li><strong>Cloud e Banco de Dados:</strong> AWS Cloud (EC2, S3, Postgres, SQLite)</li>
												<li><strong>Visualização de Dados:</strong> Metabase Visualization</li>

											</ul>
											<ul class="actions">
												<li><a href="#" class="button">Saiba mais</a></li>
											</ul>
										</article>
										<article>
											<a href="https://github.com/GabrielAlvesDS/house_rocket_streamlit" class="image"><img src="images/data_analysis.jpg" alt="" /></a>
											<h3>Identificação de imóveis para compra e revenda a fim de maximizar o lucro</h3>
											<p>Identificação de imóveis abaixo do preço médio de venda e definição do preço ideal de revenda, a partir de uma análise exploratória de dados em Python. <a href="https://gabrielalvesds-house-rocket-streamlit-dashboard-wobeve.streamlit.app/">Acesse o app e analise os dados.</a></p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Numpy, Seaborn</li>
												<li><strong>Ambientes de Desenvolvimento:</strong> Anaconda, PyCharm, Jupyter Notebook</li>
												<li><strong>Visualização de Dados:</strong> Mapas interativos com Plotly, Folium</li>
												<li><strong>Cloud:</strong> Heroku Cloud</li>
												<li><strong>Framework Web:</strong> Streamlit</li>
											
											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/house_rocket_streamlit" class="button">Saiba mais</a></li>
											</ul>
										</article>
									</div>
								</section>

								<!-- Section -->
									<section>
										<header class="major">
											<h2>Entre em contato: </h2>
										</header>
										<p>Sinta-se à vontade para entrar em contato.</p>
										<ul class="contact">
											<li class="icon solid fa-envelope"><a href="#">gabriel.cavalcante.alves@gmail.com</a></li>
											<li class="icon brands fa-linkedin"><a href="https://www.linkedin.com/in/gabriel-alves-ds">www.linkedin.com/in/gabriel-alves-ds</a></li>
											<li class="icon brands fa-google"><a href="https://www.cloudskillsboost.google/public_profiles/d6c72e12-ed4a-43c7-bf85-54f01c7c60c7">Google Cloud Skills Boost - Badges</a></li>
										</ul>
									</section>

						</div>
					</div>



			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
