<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Portfólio de projetos de dados</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Portfólio</strong> de projetos de dados</a>
								</header>

							<!-- Banner -->
								<section id="banner">
									<div class="content">
										<header>
											<h1>Olá, seja muito bem-vindo (a) ao meu portfólio de projetos de Dados.</h1>
										</header>
										<p>Nessa página, eu demonstro minhas habilidades de resolver problemas de negócio utilizando conceitos e ferramentas de Dados, através de projetos com dados públicos.</p>
										<p>Você vai encontrar também, minhas experiências profissionais, habilidades, ferramentas e conceitos envolvendo a área de Dados.</p>
										<p></p>
										<p>Sinta-se à vontade para entrar em contato através dos links no final da página.</p>
									</div>
									<span class="image object">
										<img src="images/profile_picture2.jpg" alt="" />
									</span>
								</section>

								<!-- Content -->
									<section>
										<header class="main">
											<h1>Sobre mim</h1>
										</header>

										<!-- Content -->
											<p>Meu nome é Gabriel Alves, sou formado em Ciências Econômicas e acumulo mais de 7 anos de experiência, tendo atuado como Consultor de Risco em empresas como EY e Deloitte. Durante minha trajetória, desenvolvi uma visão analítica apurada e a habilidade de transformar dados complexos em insights estratégicos.</p>
											<p>Atualmente, trabalho como Analista de Dados especializado em Big Data na Tahto, onde contribuo ativamente para a automação de processos de ETL, estruturação de indicadores e KPIs, além da criação e manutenção de dashboards e relatórios automatizados.</p>
											<p>Meu objetivo é consolidar minha carreira na área de dados, assumindo o papel de Engenheiro de Dados, com foco em aprimorar a tomada de decisões empresariais por meio de soluções orientadas por dados. Para isso concluí recentemente uma pós-graduação em Inteligência Artificial com ênfase em Machine Learning, consolidando meus conhecimentos nessa área. Estou motivado a contribuir para a inovação e o sucesso de projetos, oferecendo insights valiosos para potencializar resultados e direcionar estratégias.</p>
											</section>

							<!-- Section -->
								<section>
								    <header class="major">
								        <h1>Habilidades</h1>
								    </header>
								    <div class="features">
								        <article>
								            <span class="icon solid fa-code"></span>
								            <div class="content">
								                <h3>Programação & Manipulação de Dados</h3>
								                <ul>
								                    <li>Linguagens de Programação: Python, SQL</li>
								                    <li>Manipulação de Dados: Pandas, PySpark</li>
								                </ul>
								            </div>
								        </article>
								        <article>
								            <span class="icon solid fa-database"></span>
								            <div class="content">
								                <h3>Arquitetura & Modelagem de Dados</h3>
								                <ul>
								                    <li>Modelagem de Dados: OLAP, OLTP, Star Schema, Snowflake Schema</li>
								                    <li>Data Warehouses & Data Lakes: BigQuery, Delta Lake</li>
								                    <li>ETL/ELT: Apache Airflow, dbt, JETL</li>
								                </ul>
								            </div>
								        </article>
								        <article>
								            <span class="icon solid fa-cogs"></span>
								            <div class="content">
								                <h3>Processamento & Computação Distribuída</h3>
								                <ul>
								                    <li>Frameworks de Processamento: Apache Spark</li>
								                    <li>Computação em Lote: Apache Beam, Databricks</li>
								                </ul>
								            </div>
								        </article>
								        <article>
								            <span class="icon solid fa-cloud"></span>
								            <div class="content">
								                <h3>Infraestrutura & Cloud Computing</h3>
								                <ul>
								                    <li>Plataformas Cloud: GCP (BigQuery, Dataflow), Azure (Data Factory, Synapse)</li>
								                    <li>Containers & Orquestração: Docker</li>
								                </ul>
								            </div>
								        </article>
								        <article>
								            <span class="icon solid fa-hdd"></span>
								            <div class="content">
								                <h3>Armazenamento & Bancos de Dados</h3>
								                <ul>
								                    <li>Bancos Relacionais (SQL): Oracle, PostgreSQL, SQL Server</li>
								                    <li>Formatos de Arquivos: Parquet, JSON, Delta</li>
								                </ul>
								            </div>
								        </article>
								    </div>
								</section>

								<!-- Experiência -->
									<section>
										<header class="main">
											<h1>Experiências profissionais</h1>
										</header>
											<h2 id="content">Analista de dados Sr.</h2>
											<p>Na posição atual como Analista de Dados Sênior com ênfase em Big Data na Tahto, venho desempenhando um papel crucial na estruturação de indicadores e Dashboards. Ao longo dos últimos meses, concentrei meus esforços na automação desses processos, proporcionando uma análise eficiente e detalhada das principais métricas. Minha abordagem orientada para resultados tem sido fundamental para o sucesso dessas iniciativas, reforçando minha expertise em Big Data e Ciência de Dados.</p>
											<h2 id="content">Consultoria de Riscos</h2>
											<p>Com uma carreira abrangendo mais de seis anos em consultoria nas empresas BKR – Lopes e Machado Auditores, Deloitte, Inetum e EY, destaco minha constante busca por uma abordagem analítica em todas as entregas, com foco primordial em dados. Ao longo desse período, liderei a estruturação de metodologias voltadas para a área de controles internos na BKR, implementei a automação do preenchimento de processos e conduzi treinamentos de conscientização LGPD na Inetum. Na Deloitte, participei ativamente da elaboração de Dashboards para avaliação de desempenho e otimização de processos. Já na EY, contribuí significativamente para o design de um dashboard estratégico direcionado à gestão de riscos em Fundos de Pensão. Essa jornada diversificada e dinâmica reflete meu compromisso constante em proporcionar soluções analíticas e impulsionar resultados eficazes em cada projeto.</p>											
								</section>
							<!-- Section -->
								<section>
									<header class="major">
										<h2>Projetos em Ciência de Dados</h2>
									</header>
										<p>Durante minha jornada na Ciência de Dados, dediquei-me à criação de soluções para desafios empresariais reais, utilizando dados públicos provenientes de sites e competições de Ciência de Dados. Cada projeto que apresentarei a seguir representa desde a identificação dos desafios de negócio até a implementação efetiva dos algoritmos em produção, fazendo uso de avançadas ferramentas de Cloud Computing. Vale mencionar que, devido ao seu alto custo operacional, alguns projetos foram retirados de produção; entretanto, os códigos correspondentes estão disponíveis no GitHub para referência e aprendizado contínuo.</p>
									<div class="posts">
										<article>
											<a href="https://github.com/GabrielAlvesDS/File-Insight" class="image"><img src="images/file-insight.png" alt="" /></a>
											<h3>File-Insight - Análise de Arquivos CSV e DOCX com LangChain e OpenAI</h3>
											<p>Este projeto implementa uma aplicação web que permite aos usuários fazer upload de arquivos CSV ou DOCX e realizar consultas automatizadas sobre os dados, utilizando a API OpenAI e LangChain.</p>
											<p>A aplicação foi construída com Streamlit e utiliza um agente de LangChain para processar as consultas de CSV e extrair informações de arquivos DOCX.</p>

											<p><a href="https://file-insight.onrender.com/">Experimente o File-Insight aqui</a></p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
                                                                                        	<li><strong>Versionamento e Deploy:</strong> Git, GitHub, Render</li>
                                                                                        	<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas</li>
                                                                                        	<li><strong>Desenvolvimento Web:</strong> Streamlit</li>
                                                                                            	<li><strong>IA e Modelos de Linguagem:</strong> LangChain, OpenAI API</li>

											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/File-Insight" class="button">Saiba mais</a></li>
											</ul>
										</article>


										<article>
											<a href="https://github.com/GabrielAlvesDS/LSTM-TempForecast" class="image"><img src="images/LSTM_Forecast.png" alt="" /></a>
											<h3>LSTM_Forecast - Temperature Forecasting Long Short Term Model</h3>
											<p>Um modelo LSTM foi desenvolvido para prever a temperatura do ar para a próxima hora com base nas últimas 24 horas de dados históricos. O modelo apresentou um desempenho excepcional, com um Erro Quadrático Médio (MSE) de 0,80 e um Erro Quadrático Médio da Raiz (RMSE) de 0,89, indicando que as previsões de temperatura desviaram menos de 1 grau Celsius em média.</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitHub</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Machine Learning:</strong> Redes Neurais, MLP, GRU, LSTM</li>

											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/LSTM-TempForecast" class="button">Saiba mais</a></li>
											</ul>
										</article>

										

										<article>
											<a href="https://github.com/GabrielAlvesDS/TempTrack" class="image"><img src="images/TempTrack.png" alt="" /></a>
											<h3>TempTrack - Time Series Temperature Forecasting Model</h3>
											<p>Este projeto de análise de séries temporais envolve o desenvolvimento de dois modelos para prever a temperatura horária ao longo de um ano, utilizando Prophet e XGBoost. O objetivo é avaliar a eficácia de cada modelo e determinar qual deles oferece o melhor desempenho.</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitHub</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Previsão:</strong> Prophet, XGBoost</li>

											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/TempTrack" class="button">Saiba mais</a></li>
											</ul>
										</article>

										<article>
											<a href="https://github.com/GabrielAlvesDS/CarPrice_Pro" class="image"><img src="images/CarPrice Pro.jpg" alt="" /></a>
											<h3>CarPrice Pro - Precificador de carro</h3>
											<p>Consiste em um projeto com base em dados extraídos da API do WebMotors que busca criar um modelo de predição do valor de venda de um carro dado suas características. Criando uma interface com o Telegram para consultas.</p>

											<p><a href="https://docs.google.com/spreadsheets/d/1qpC4JApSCmDyH4fDHAwcsKcGn2nrY4JOtJ10SspNqKU/edit?gid=0#gid=0">Experimente o CarPrice Pro aqui</a></p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitHub, Render</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Machine Learning:</strong> Logistic Regression, K-Nearest Neighbors, Random Forest, XGBoost Classifier</li>
												<li><strong>Automação e Desenvolvimento Web:</strong> Google Apps Script, Flask</li>

											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/CarPrice_Pro" class="button">Saiba mais</a></li>
											</ul>
										</article>										

										<article>
											<a href="https://github.com/GabrielAlvesDS/fraud_risk_defender" class="image"><img src="images/fraud_risk.jpg" alt="" /></a>
											<h3>Fraud Risk Defender - Detecção de fraudes</h3>
											<p>Elaboração de um modelo de classificação para detecção de fraude em transações financeiras realizadas através de dispositivos móveis. Com 99,58% de Recall e 99,79% de ROC AUC, onde no cenário estipulado geraria uma receita de 537 milhões (moeda não especificada).</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitHub</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Machine Learning:</strong> Logistic Regression, K-Nearest Neighbors, Random Forest, XGBoost Classifier, Gradient Boosting</li>
												<li><strong>Seleção de Features:</strong> Boruta</li>

											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/fraud_risk_defender" class="button">Saiba mais</a></li>
											</ul>
										</article>
										
										<article>
											<a href="https://github.com/GabrielAlvesDS/rossmann-sale-prediction" class="image"><img src="images/sales_prediction.jpg" alt="" /></a>
											<h3>Construção de um modelo de predição de vendas para uma rede de Drogarias</h3>
											<p>Construção de um algoritmo de Machine Learning para prever vendas com 6 semanas de antecedência em uma rede de farmácias da Europa. O algoritmo de regressão treinado possui 10,5% de MAPE.</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitHub, Render</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Machine Learning:</strong> Random Forest, XGBoost e Lasso</li>
												<li><strong>Integração e Automação:</strong> API do Telegram</li>
											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/rossmann-sale-prediction" class="button">Saiba mais</a></li>
											</ul>
										</article>
										<article>
											<a href="https://github.com/GabrielAlvesDS/Health-Insurance-Cross-Sell/tree/main" class="image"><img src="images/customer_loyalty.jpg" alt="" /></a>
											<h3>Health Insurance Cross Sell - Ranqueamento dos clientes mais propensos a comprar um novo produto.</h3>
											<p>Identificação de clientes propensos a adquirir um novo produto de uma seguradora. Implantando um modelo de machine learning conectado a uma API e uma planilha do Google Sheets, conseguindo triplicar a eficiência do time de Vendas.</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitHub, Render</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Machine Learning:</strong> Scikit-Learn, XGBoost</li>
												<li><strong>Desenvolvimento Web e Automação:</strong> Flask, Pickle, Google Apps Script, Google Sheets</li>

											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/Health-Insurance-Cross-Sell/tree/main" class="button">Saiba mais</a></li>
											</ul>
										</article>
										<article>
											<a href="#" class="image"><img src="images/clustering.jpg" alt="" /></a>
											<h3>Construção de um programa de fidelidade com clusterização de clientes</h3>
											<p>Eu usei Python, Estatística e técnicas não-supervisionadas de Machine Learning para segmentar um grupo de clientes com base em suas características de performance de compra, a fim de selecionar grupos de clientes para formar um programa de Fidelidade com o objetivo de aumentar a receita da empresa. E o resultado dessa solução, caso fosse implementada, seria de R$ 15MM de dólares de receita anual.</p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Versionamento e Deploy:</strong> Git, GitLab, GitHub</li>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Matplotlib, Seaborn, Jupyter Notebook</li>
												<li><strong>Modelos de Machine Learning:</strong> K-Means, Hierarchical Clustering, DBScan</li>
												<li><strong>Cloud e Banco de Dados:</strong> AWS Cloud (EC2, S3, Postgres, SQLite)</li>
												<li><strong>Visualização de Dados:</strong> Metabase Visualization</li>

											</ul>
											<ul class="actions">
												<li><a href="#" class="button">Saiba mais</a></li>
											</ul>
										</article>
										<article>
											<a href="https://github.com/GabrielAlvesDS/house_rocket_streamlit" class="image"><img src="images/data_analysis.jpg" alt="" /></a>
											<h3>Identificação de imóveis para compra e revenda a fim de maximizar o lucro</h3>
											<p>Identificação de imóveis abaixo do preço médio de venda e definição do preço ideal de revenda, a partir de uma análise exploratória de dados em Python. <a href="https://gabrielalvesds-house-rocket-streamlit-dashboard-wobeve.streamlit.app/">Acesse o app e analise os dados.</a></p>
											<h4>As ferramentas utilizadas foram:</h4>
											<ul>
												<li><strong>Linguagens e Bibliotecas:</strong> Python, Pandas, Numpy, Seaborn</li>
												<li><strong>Ambientes de Desenvolvimento:</strong> Anaconda, PyCharm, Jupyter Notebook</li>
												<li><strong>Visualização de Dados:</strong> Mapas interativos com Plotly, Folium</li>
												<li><strong>Cloud:</strong> Heroku Cloud</li>
												<li><strong>Framework Web:</strong> Streamlit</li>
											
											</ul>
											<ul class="actions">
												<li><a href="https://github.com/GabrielAlvesDS/house_rocket_streamlit" class="button">Saiba mais</a></li>
											</ul>
										</article>
									</div>
								</section>

								<!-- Section -->
									<section>
										<header class="major">
											<h2>Entre em contato: </h2>
										</header>
										<p>Sinta-se à vontade para entrar em contato.</p>
										<ul class="contact">
											<li class="icon solid fa-envelope"><a href="#">gabriel.cavalcante.alves@gmail.com</a></li>
											<li class="icon brands fa-linkedin"><a href="https://www.linkedin.com/in/gabriel-alves-ds">www.linkedin.com/in/gabriel-alves-ds</a></li>
											<li class="icon brands fa-google"><a href="https://www.cloudskillsboost.google/public_profiles/d6c72e12-ed4a-43c7-bf85-54f01c7c60c7">Google Cloud Skills Boost - Badges</a></li>
										</ul>
									</section>

						</div>
					</div>



			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
